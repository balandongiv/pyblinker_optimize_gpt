{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# üëÅÔ∏è **Step 1: Visual Validation of Blink Annotations Against Signal Data**\n",
    "\n",
    "This is the **first step** in the blink analysis pipeline. It focuses on **visually verifying** that the manually labeled blink events‚Äîannotated by a human expert in **CVAT**‚Äîare properly aligned with physiological signal data:\n",
    "\n",
    "* **EAR (Eye Aspect Ratio)** time series\n",
    "* **EEG/EOG signals**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Purpose of This Step**\n",
    "\n",
    "Before performing any analysis, we need to **validate the accuracy** of the blink annotations. These labels were created **manually in CVAT**, by identifying:\n",
    "\n",
    "* üü¢ When the blink **starts**\n",
    "* üî¥ When the eye is **fully closed** (minimum EAR)\n",
    "* üü¢ When the blink **ends**\n",
    "\n",
    "These annotations are made on a **frame basis** (e.g., 30 Hz video) and must be **mapped** to high-frequency sample-based physiological signals (e.g., EEG at 500‚Äì1000 Hz).\n",
    "This phase ensures the labels visually tally with the signal data before any downstream processing.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® **What This Script Does**\n",
    "\n",
    "* Loads raw `.fif` eye-tracking + EEG data and CVAT `.zip` annotations\n",
    "* Extracts blink intervals and converts them to time-series sample indices\n",
    "* Plots:\n",
    "\n",
    "  * EAR and EEG signals\n",
    "  * Blink annotations (start, min, end) overlaid on signals\n",
    "* Exports visual PDF reports for inspection\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ **Inputs Required**\n",
    "\n",
    "| File                      | Description                                       |\n",
    "| ------------------------- | ------------------------------------------------- |\n",
    "| `S01_20170519_043933.fif` | Raw physiological data (EEG, EAR, etc.)           |\n",
    "| `S01_20170519_043933.zip` | Blink annotations from CVAT (JSON/XML inside ZIP) |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **How Blink Intervals Are Extracted**\n",
    "\n",
    "The function `extract_blink_durations(...)` handles the critical step of **converting frame-based CVAT annotations** into **sample indices** that align with high-frequency time-series data (e.g., EEG):\n",
    "\n",
    "```python\n",
    "def extract_blink_durations(annotation_df, frame_offset, sfreq, video_fps):\n",
    "    ...\n",
    "```\n",
    "\n",
    "### üõ†Ô∏è What It Does:\n",
    "\n",
    "* Processes blink annotations that appear in **triplets**:\n",
    "  `start ‚Üí min ‚Üí end`\n",
    "* Subtracts a **frame offset** (if any cropping or indexing shift is needed)\n",
    "* Converts CVAT **video frame indices** to **sample indices** for time series, using:\n",
    "\n",
    "  ```\n",
    "  sample_index = (frame_index - offset) * (sfreq / video_fps)\n",
    "  ```\n",
    "\n",
    "### üì§ Output Columns:\n",
    "\n",
    "| Column                               | Description                                           |\n",
    "| ------------------------------------ | ----------------------------------------------------- |\n",
    "| `startFrame`, `endFrame`, `minFrame` | Original CVAT frame indices                           |\n",
    "| `startBlinks_cvat`, `...`            | Adjusted frame indices after offset                   |\n",
    "| `startBlinks`, `...`                 | Final sample indices aligned to time series           |\n",
    "| `blink_type`                         | Type/category of blink (e.g., 'blink', 'long\\_blink') |\n",
    "\n",
    "‚úÖ This ensures that annotation markers precisely line up with the raw signals.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## üìò **Overview of the 3 Steps**\n",
    "\n",
    "| Step | Description                                      |\n",
    "| ---- | ------------------------------------------------ |\n",
    "| 1Ô∏è‚É£  | Visualize overall time-series signal (EAR + EEG) |\n",
    "| 2Ô∏è‚É£  | Plot each blink with start, min, and end markers |\n",
    "| 3Ô∏è‚É£  | Save a consolidated visual report using MNE      |\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ **Step 1a: Plot the Full Time-Series Signal**\n",
    "\n",
    "This helps you check for:\n",
    "\n",
    "* Overall quality of the data\n",
    "* Expected variations in EAR and EEG/EOG\n",
    "* Regions of interest for blinks\n",
    "\n",
    "```python\n",
    "raw.plot(\n",
    "    picks=['avg_ear', 'E8'],\n",
    "    block=True,\n",
    "    show_scrollbars=False,\n",
    "    title='avg_ear Blink Signal'\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Step 1b: Inspect Blink Intervals One-by-One**\n",
    "\n",
    "Each blink is annotated by a triplet: `start`, `min`, `end`. This step plots those over the EAR signal for **detailed inspection**.\n",
    "\n",
    "```python\n",
    "for _, row in blink_df.iterrows():\n",
    "    plot_with_annotation_lines(\n",
    "        raw=raw,\n",
    "        start_frame=row['startBlinks'],\n",
    "        end_frame=row['endBlinks'],\n",
    "        mid_frame=row['blink_min'],\n",
    "        picks='avg_ear',\n",
    "        sfreq=sfreq,\n",
    "    )\n",
    "```\n",
    "\n",
    "This lets you manually verify that annotations are consistent with the physiological signal dips and recoveries.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Step 1c: Generate HTML Report with MNE**\n",
    "\n",
    "Instead of viewing blink events one by one, this step **automatically generates a consolidated HTML report** using **MNE‚Äôs reporting tool**.\n",
    "\n",
    "```python\n",
    "generate_blink_reports(\n",
    "    raw=raw,\n",
    "    blink_df=blink_df,\n",
    "    picks='avg_ear',\n",
    "    sfreq=sfreq,\n",
    "    output_dir='blink_reports',\n",
    "    base_filename='blink_report',\n",
    "    max_events_per_report=40\n",
    ")\n",
    "```\n",
    "\n",
    "### üìÇ Output:\n",
    "\n",
    "```\n",
    "blink_reports/\n",
    "‚îî‚îÄ‚îÄ blink_report.html\n",
    "```\n",
    "\n",
    "The report provides a scrollable interface to review blink events in bulk with annotation markers.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **Behind the Scenes: Blink Frame Mapping**\n",
    "\n",
    "The function `extract_blink_durations(...)` ensures frame-based CVAT labels are aligned with high-frequency signal data:\n",
    "\n",
    "```python\n",
    "sample_index = (frame_index - offset) * (sfreq / video_fps)\n",
    "```\n",
    "\n",
    "This mapping converts frame labels to time-series sample indices that can be plotted accurately.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **Why This Step Is Critical**\n",
    "\n",
    "‚úÖ Confirms label‚Äìsignal alignment\n",
    "‚úÖ Flags mislabeled or shifted annotations early\n",
    "‚úÖ Builds confidence in the dataset before training models or running statistics\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è **Reminder**\n",
    "\n",
    "> This is a **quality control step**.\n",
    "> Visual inspection is **mandatory** to catch any misalignments between annotations and raw signals.\n"
   ],
   "id": "a8b9cc75cf6d245f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from direct_blink_properties.util import load_fif_and_annotations,extract_blink_durations\n",
    "from direct_blink_properties.viz import generate_blink_reports,plot_with_annotation_lines\n",
    "\n",
    "# We will use subject S01 from the dataset\n",
    "fif_path = r\"C:\\Users\\balan\\IdeaProjects\\pyblinker_optimize_gpt\\data_new_pipeline\\S01_20170519_043933.fif\"\n",
    "zip_path = r\"C:\\Users\\balan\\IdeaProjects\\pyblinker_optimize_gpt\\data_new_pipeline\\S01_20170519_043933.zip\"\n",
    "\n",
    "\n",
    "# Load data\n",
    "raw, annotation_df = load_fif_and_annotations(fif_path, zip_path)\n",
    "# Extract blink intervals\n",
    "frame_offset=5\n",
    "video_fps=30\n",
    "sfreq = raw.info['sfreq']\n",
    "blink_df = extract_blink_durations(annotation_df,frame_offset,sfreq,video_fps)\n",
    "\n",
    "\n",
    "# get the sampling rate\n",
    "\n",
    "# Get overview about the time series data\n",
    "raw.plot(\n",
    "    picks=['avg_ear','E8'],\n",
    "    block=True,\n",
    "    show_scrollbars=False,\n",
    "    title='avg_ear Blink Signal'\n",
    ")\n",
    "\n",
    "\n",
    "# Get a plot by plotting the blink signal with the annotation lines\n",
    "# ‚ö†Ô∏è WARNING: Only plotting the first 10 blinks for visual inspection\n",
    "print(\"‚ö†Ô∏è WARNING: Only plotting the first 10 blink events...\")\n",
    "for _, row in  blink_df.head(10).iterrows():\n",
    "    plot_with_annotation_lines(\n",
    "        raw=raw,\n",
    "        start_frame=row['startBlinks'],\n",
    "        end_frame=row['endBlinks'],\n",
    "        mid_frame=row['blink_min'],\n",
    "        picks='avg_ear',\n",
    "        sfreq=sfreq ,\n",
    "    )\n",
    "\n",
    "# Generate a report for the blink signal\n",
    "\n",
    "generate_blink_reports(\n",
    "    raw=raw,\n",
    "    blink_df=blink_df,\n",
    "    picks='avg_ear',\n",
    "    sfreq=sfreq ,\n",
    "    output_dir='blink_reports',\n",
    "    base_filename='blink_report',\n",
    "    max_events_per_report=40\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Generate a report for the blink signal\n",
    "\n",
    "generate_blink_reports(\n",
    "    raw=raw,\n",
    "    blink_df=blink_df,\n",
    "    picks='avg_ear',\n",
    "    sfreq=sfreq ,\n",
    "    output_dir='blink_reports',\n",
    "    base_filename='blink_report',\n",
    "    max_events_per_report=40\n",
    ")"
   ],
   "id": "704a309d668bb645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
