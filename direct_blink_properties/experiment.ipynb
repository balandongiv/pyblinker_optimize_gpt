{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# üëÅÔ∏è **Step 1: Visual Validation of Blink Annotations Against Signal Data**\n",
    "\n",
    "This is the **first step** in the blink analysis pipeline. It focuses on **visually verifying** that the manually labeled blink events‚Äîannotated by a human expert in **CVAT**‚Äîare properly aligned with physiological signal data:\n",
    "\n",
    "* **EAR (Eye Aspect Ratio)** time series\n",
    "* **EEG/EOG signals**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Purpose of This Step**\n",
    "\n",
    "Before performing any analysis, we need to **validate the accuracy** of the blink annotations. These labels were created **manually in CVAT**, by identifying:\n",
    "\n",
    "* üü¢ When the blink **starts**\n",
    "* üî¥ When the eye is **fully closed** (minimum EAR)\n",
    "* üü¢ When the blink **ends**\n",
    "\n",
    "These annotations are made on a **frame basis** (e.g., 30 Hz video) and must be **mapped** to high-frequency sample-based physiological signals (e.g., EEG at 500‚Äì1000 Hz).\n",
    "This phase ensures the labels visually tally with the signal data before any downstream processing.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® **What This Script Does**\n",
    "\n",
    "* Loads raw `.fif` eye-tracking + EEG data and CVAT `.zip` annotations\n",
    "* Extracts blink intervals and converts them to time-series sample indices\n",
    "* Plots:\n",
    "\n",
    "  * EAR and EEG signals\n",
    "  * Blink annotations (start, min, end) overlaid on signals\n",
    "* Exports visual PDF reports for inspection\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ **Inputs Required**\n",
    "\n",
    "| File                      | Description                                       |\n",
    "| ------------------------- | ------------------------------------------------- |\n",
    "| `S01_20170519_043933.fif` | Raw physiological data (EEG, EAR, etc.)           |\n",
    "| `S01_20170519_043933.zip` | Blink annotations from CVAT (JSON/XML inside ZIP) |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **How Blink Intervals Are Extracted**\n",
    "\n",
    "The function `extract_blink_durations(...)` handles the critical step of **converting frame-based CVAT annotations** into **sample indices** that align with high-frequency time-series data (e.g., EEG):\n",
    "\n",
    "```python\n",
    "def extract_blink_durations(annotation_df, frame_offset, sfreq, video_fps):\n",
    "    ...\n",
    "```\n",
    "\n",
    "### üõ†Ô∏è What It Does:\n",
    "\n",
    "* Processes blink annotations that appear in **triplets**:\n",
    "  `start ‚Üí min ‚Üí end`\n",
    "* Subtracts a **frame offset** (if any cropping or indexing shift is needed)\n",
    "* Converts CVAT **video frame indices** to **sample indices** for time series, using:\n",
    "\n",
    "  ```\n",
    "  sample_index = (frame_index - offset) * (sfreq / video_fps)\n",
    "  ```\n",
    "\n",
    "### üì§ Output Columns:\n",
    "\n",
    "| Column                               | Description                                           |\n",
    "| ------------------------------------ | ----------------------------------------------------- |\n",
    "| `startFrame`, `endFrame`, `minFrame` | Original CVAT frame indices                           |\n",
    "| `startBlinks_cvat`, `...`            | Adjusted frame indices after offset                   |\n",
    "| `startBlinks`, `...`                 | Final sample indices aligned to time series           |\n",
    "| `blink_type`                         | Type/category of blink (e.g., 'blink', 'long\\_blink') |\n",
    "\n",
    "‚úÖ This ensures that annotation markers precisely line up with the raw signals.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## üìò **Overview of the 3 Steps**\n",
    "\n",
    "| Step | Description                                      |\n",
    "| ---- | ------------------------------------------------ |\n",
    "| 1Ô∏è‚É£  | Visualize overall time-series signal (EAR + EEG) |\n",
    "| 2Ô∏è‚É£  | Plot each blink with start, min, and end markers |\n",
    "| 3Ô∏è‚É£  | Save a consolidated visual report using MNE      |\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ **Step 1a: Plot the Full Time-Series Signal**\n",
    "\n",
    "This helps you check for:\n",
    "\n",
    "* Overall quality of the data\n",
    "* Expected variations in EAR and EEG/EOG\n",
    "* Regions of interest for blinks\n",
    "\n",
    "```python\n",
    "raw.plot(\n",
    "    picks=['avg_ear', 'E8'],\n",
    "    block=True,\n",
    "    show_scrollbars=False,\n",
    "    title='avg_ear Blink Signal'\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Step 1b: Inspect Blink Intervals One-by-One**\n",
    "\n",
    "Each blink is annotated by a triplet: `start`, `min`, `end`. This step plots those over the EAR signal for **detailed inspection**.\n",
    "\n",
    "```python\n",
    "for _, row in blink_df.iterrows():\n",
    "    plot_with_annotation_lines(\n",
    "        raw=raw,\n",
    "        start_frame=row['startBlinks'],\n",
    "        end_frame=row['endBlinks'],\n",
    "        mid_frame=row['blink_min'],\n",
    "        picks='avg_ear',\n",
    "        sfreq=sfreq,\n",
    "    )\n",
    "```\n",
    "\n",
    "This lets you manually verify that annotations are consistent with the physiological signal dips and recoveries.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Step 1c: Generate HTML Report with MNE**\n",
    "\n",
    "Instead of viewing blink events one by one, this step **automatically generates a consolidated HTML report** using **MNE‚Äôs reporting tool**.\n",
    "\n",
    "```python\n",
    "generate_blink_reports(\n",
    "    raw=raw,\n",
    "    blink_df=blink_df,\n",
    "    picks='avg_ear',\n",
    "    sfreq=sfreq,\n",
    "    output_dir='blink_reports',\n",
    "    base_filename='blink_report',\n",
    "    max_events_per_report=40\n",
    ")\n",
    "```\n",
    "\n",
    "### üìÇ Output:\n",
    "\n",
    "```\n",
    "blink_reports/\n",
    "‚îî‚îÄ‚îÄ blink_report.html\n",
    "```\n",
    "\n",
    "The report provides a scrollable interface to review blink events in bulk with annotation markers.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **Behind the Scenes: Blink Frame Mapping**\n",
    "\n",
    "The function `extract_blink_durations(...)` ensures frame-based CVAT labels are aligned with high-frequency signal data:\n",
    "\n",
    "```python\n",
    "sample_index = (frame_index - offset) * (sfreq / video_fps)\n",
    "```\n",
    "\n",
    "This mapping converts frame labels to time-series sample indices that can be plotted accurately.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **Why This Step Is Critical**\n",
    "\n",
    "‚úÖ Confirms label‚Äìsignal alignment\n",
    "‚úÖ Flags mislabeled or shifted annotations early\n",
    "‚úÖ Builds confidence in the dataset before training models or running statistics\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è **Reminder**\n",
    "\n",
    "> This is a **quality control step**.\n",
    "> Visual inspection is **mandatory** to catch any misalignments between annotations and raw signals.\n"
   ],
   "id": "a8b9cc75cf6d245f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from direct_blink_properties.util import load_fif_and_annotations,extract_blink_durations\n",
    "from direct_blink_properties.viz import generate_blink_reports,plot_with_annotation_lines\n",
    "\n",
    "# We will use subject S01 from the dataset\n",
    "fif_path = r\"C:\\Users\\balan\\IdeaProjects\\pyblinker_optimize_gpt\\data_new_pipeline\\S01_20170519_043933.fif\"\n",
    "zip_path = r\"C:\\Users\\balan\\IdeaProjects\\pyblinker_optimize_gpt\\data_new_pipeline\\S01_20170519_043933.zip\"\n",
    "\n",
    "\n",
    "# Load data\n",
    "raw, annotation_df = load_fif_and_annotations(fif_path, zip_path)\n",
    "# Extract blink intervals\n",
    "frame_offset=5\n",
    "video_fps=30\n",
    "sfreq = raw.info['sfreq']\n",
    "blink_df = extract_blink_durations(annotation_df,frame_offset,sfreq,video_fps)\n",
    "\n",
    "\n",
    "# get the sampling rate\n",
    "\n",
    "# Get overview about the time series data\n",
    "raw.plot(\n",
    "    picks=['avg_ear','E8'],\n",
    "    block=True,\n",
    "    show_scrollbars=False,\n",
    "    title='avg_ear Blink Signal'\n",
    ")\n",
    "\n",
    "\n",
    "# Get a plot by plotting the blink signal with the annotation lines\n",
    "# ‚ö†Ô∏è WARNING: Only plotting the first 10 blinks for visual inspection\n",
    "print(\"‚ö†Ô∏è WARNING: Only plotting the first 10 blink events...\")\n",
    "for _, row in  blink_df.head(10).iterrows():\n",
    "    plot_with_annotation_lines(\n",
    "        raw=raw,\n",
    "        start_frame=row['startBlinks'],\n",
    "        end_frame=row['endBlinks'],\n",
    "        mid_frame=row['blink_min'],\n",
    "        picks='avg_ear',\n",
    "        sfreq=sfreq ,\n",
    "    )\n",
    "\n",
    "# Generate a report for the blink signal\n",
    "\n",
    "generate_blink_reports(\n",
    "    raw=raw,\n",
    "    blink_df=blink_df,\n",
    "    picks='avg_ear',\n",
    "    sfreq=sfreq ,\n",
    "    output_dir='blink_reports',\n",
    "    base_filename='blink_report',\n",
    "    max_events_per_report=40\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Generate a report for the blink signal\n",
    "\n",
    "generate_blink_reports(\n",
    "    raw=raw,\n",
    "    blink_df=blink_df,\n",
    "    picks='avg_ear',\n",
    "    sfreq=sfreq ,\n",
    "    output_dir='blink_reports',\n",
    "    base_filename='blink_report',\n",
    "    max_events_per_report=40\n",
    ")"
   ],
   "id": "704a309d668bb645"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8c3e2cf54848831e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below is a detailed breakdown of each proposed refinement method, its underlying principle, and why it tends to boost the **kept\\_ratio** (i.e. the fraction of epochs that survive your zero-crossing and gap-size filter) while preserving‚Äîor often improving‚Äîpeak positivity.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. High-pass Butterworth\n",
    "\n",
    "**What it does:** removes very low-frequency (DC and drift) components below your cutoff (e.g. 0.1‚Äì0.3 Hz), letting blinks (which are relatively fast, \\~1‚Äì10 Hz) stand out.\n",
    "**Why it helps:** any slow baseline wander that shifts an entire blink epoch below zero is eliminated; peaks become clearly above zero. The smooth roll-off of a Butterworth filter avoids ringing artifacts that could generate false zero crossings. Tuning the cutoff lets you trade off between drift removal and waveform distortion.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Band-pass (0.1‚Äì15 Hz)\n",
    "\n",
    "**What it does:** cascades a high-pass at \\~0.1 Hz with a low-pass at \\~15 Hz in one go.\n",
    "**Why it helps:** not only removes baseline drifts, but also attenuates high-frequency sensor noise or muscle spikes. A cleaner, band-limited blink waveform has more pronounced peaks and cleaner zero crossings on either side.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Asymmetric Least Squares (ALS) baseline subtraction\n",
    "\n",
    "**What it does:** iteratively fits a smooth baseline under the signal by penalizing deviations more strongly in one direction (typically pushing the baseline below the waveform).\n",
    "**Why it helps:** ALS adapts locally to each blink‚Äôs neighborhood, capturing subtle curvature in the baseline that linear or polynomial detrending can miss. Subtracting this ‚Äòenvelope‚Äô makes all blinks protrude positively.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. airPLS (adaptive iteratively re-weighted penalized LS)\n",
    "\n",
    "**What it does:** a refined version of ALS that re-weights each sample‚Äôs penalty based on its residual, yielding a baseline that clings even more to the true minima.\n",
    "**Why it helps:** provides superior baseline estimation in the presence of overlapping blinks or outlier spikes. By automatically down-weighting large positive excursions (the blinks), the baseline stays under them, ensuring positive peaks remain above zero.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Wavelet baseline removal\n",
    "\n",
    "**What it does:** decomposes the signal into wavelet coefficients across scales; you zero out the lowest-frequency (coarse) component and reconstruct only from the higher-frequency details.\n",
    "**Why it helps:** wavelets adapt to both time and frequency, so they remove drift without smearing the blink shape. The reconstructed waveform highlights the transient ‚Äúbell-shapes‚Äù of blinks while suppressing slow, non-oscillatory drift.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Whittaker smoother\n",
    "\n",
    "**What it does:** solves a penalized least-squares problem‚Äîminimizing the difference to the signal plus a penalty on curvature‚Äîto compute a smooth baseline, then subtracts it.\n",
    "**Why it helps:** like ALS/airPLS but faster and guaranteed stable: the penalty on the second derivative forces a very smooth baseline. Subtracting it recenters each blink without introducing high-frequency artefacts.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Rolling median baseline\n",
    "\n",
    "**What it does:** computes, for each point, the median of its neighborhood (e.g. ¬±250 samples), creating a sliding-window ‚Äúbaseline‚Äù that tracks slow trends.\n",
    "**Why it helps:** the median is robust to the large transient spikes of blinks, so the rolling median sits under the peaks. Subtracting it recenters each epoch around zero-mean, making peaks positive and zero crossings reliable.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Rolling 5th-percentile baseline\n",
    "\n",
    "**What it does:** like the median filter but takes a low quantile (e.g. 5th percentile) in each window.\n",
    "**Why it helps:** because the baseline is estimated from a low percentile, it necessarily lies below almost all blink samples. Subtracting it strongly accentuates blinks and virtually guarantees that every epoch‚Äôs max is positive.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Morphological closing ‚Üí opening\n",
    "\n",
    "**What it does:** treats the waveform as a 1-D ‚Äúimage‚Äù: closing (dilation then erosion) removes narrow dips/spikes, then opening (erosion then dilation) removes narrow peaks, yielding a smooth envelope. Subtracting this morphological baseline highlights transients.\n",
    "**Why it helps:** morphological operations capture the overall envelope of the data without fitting polynomials. The resulting baseline sits under broad blinks but ignores sharp artefacts, so subtraction leaves clean, positive-headed blink shapes.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. LOESS (locally-weighted regression)\n",
    "\n",
    "**What it does:** fits, at each timepoint, a local linear (or low-order) regression to its neighbors weighted by distance, yielding a smooth, adaptive baseline.\n",
    "**Why it helps:** LOESS is nonparametric and can model complex baseline curvature. Subtracting it recenters the signal around zero while preserving the fine shape of each blink, so positive peaks and zero crossings align correctly.\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Empirical Mode Decomposition (EMD) reconstruction\n",
    "\n",
    "**What it does:** decomposes the signal into intrinsic mode functions (IMFs) from highest to lowest frequency. Summing only the first few high-frequency IMFs reconstructs the transient component.\n",
    "**Why it helps:** by dropping low-frequency (IMF) modes that carry drift, you isolate the blink transients themselves. The reconstructed signal is naturally zero-mean around each blink and all peaks are positive.\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Sliding-window z-score\n",
    "\n",
    "**What it does:** for each sample, computes its mean and standard deviation over a local window, then transforms to $(x-Œº)/œÉ$.\n",
    "**Why it helps:** this both recenters (mean=0) and normalizes the local amplitude (œÉ=1). Blinks pop out as large positive z-scores; any residual drift is removed. Zero crossings now reliably bracket the positive z-score peaks.\n",
    "\n",
    "---\n",
    "\n",
    "#### Bringing it all together\n",
    "\n",
    "By adding these methods into your `REFINERS` registry and exploring their parameter grids, you‚Äôll cover:\n",
    "\n",
    "* **Classic digital filters** (1 & 2)\n",
    "* **Robust baseline fits** (3, 4, 6)\n",
    "* **Statistical smoothing** (7, 8, 12)\n",
    "* **Morphological & wavelet** (5, 9)\n",
    "* **Adaptive, data-driven decompositions** (10, 11)\n",
    "\n",
    "In practice, **ALS**, **airPLS**, and **band-pass/high-pass** almost always crack a kept\\_ratio ‚â• 0.95 while keeping peak fractions at 1.0. Once you‚Äôve identified the top contenders, you can hone in on their parameter ranges (e.g. window sizes, penalty Œª, filter cutoffs) to squeeze out that final few percent of retention without sacrificing peak integrity.\n"
   ],
   "id": "953e2440a7a074c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2af82a7bd7fd350"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
